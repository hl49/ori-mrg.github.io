---
# Banner
banner:
  title: "The Mobile Robotics Group"
  carousel_images:
    - src: "/images/banner/restaurant_2025.jpg"
      alt: "MRG social 2025"
    - src: "/images/banner/banner_2020.png"
      alt: "Banner remote 2020"
    - src: "/images/banner/sax.png"
      alt: "SAX 2021"

# Intro
intro:
  title: "About us"
  content: "The Mobile Robotics Group (MRG) is the original group that grew into today’s [Oxford Robotics Institute (ORI)](https://ori.ox.ac.uk/). Since 2005, our mission has been to tackle the hardest problems in mobile autonomy: answering the fundamental questions of *“Where am I?”* and *“What surrounds me?”* on real robots operating in complex, real-world environments.  

  We have a proud systems heritage, taking on ambitious field deployments that stress-test technology and expose what needs to be solved next. Over the years, our work has led the way in large-scale SLAM, localisation from vision and lidar, and the practical engineering of autonomous systems. In 2014, MRG operated the first autonomous vehicle on UK public roads — a landmark now celebrated at the National Science Museum.  

  Today, our focus is on the next generation of autonomy: scalable systems that fuse novel sensing, machine learning, and robotics insights to make autonomy robust, reliable, and useful in the wild."

# Features
features:
  - title: "Autonomous vehicles"
    image: "/images/frontpage/penfold.png"
    content: "From our earliest days, vehicles have been central to MRG’s research. In 2014, we achieved a UK first: operating a self-driving car on public roads. Since then, our work has advanced all aspects of autonomous driving — perception, localisation, planning, and safety. Our research has seeded prestigious datasets, influential publications, and the spin-out company [OXA](https://oxa.tech/), bringing Oxford autonomy to the world."

  - title: "Uncommon sensing modalities"
    image: "/images/frontpage/radar.png"
    content: "We pioneered the use of radar for autonomy, demonstrating how robust long‑range sensing complements vision and lidar in challenging conditions such as fog, rain, and night-time driving. Today, MRG continues to explore unconventional and underused sensing technologies — from ground-based radar to satellite signals and CCTV networks — to deliver reliable autonomy in environments where conventional sensors alone are not enough."

  - title: "Scene understanding"
    image: "/images/frontpage/gammassl.png"
    content: "Beyond knowing ‘where we are,’ robots must understand complex, dynamic scenes. Our research develops methods for semantic mapping, object recognition, and long-term scene interpretation. We combine classical robotics with deep learning to make environments legible and predictable for autonomous systems."

  - title: "Data synthesis"
    image: "/images/frontpage/neuralfloors.png"
    content: "Real-world data is costly and imperfect. We investigate approaches for generating high-quality synthetic data — from simulated environments to neural rendering — to augment training, accelerate development, and improve robustness of autonomous systems in the field."

  - title: "Dataset and data analysis"
    image: "/images/frontpage/dna.jpg"
    content: "Hugoplate is a comprehensive starter template that includes everything you need to get started with your Hugo project. What's Included in Hugoplate"

  - title: "Dataset recording and sharing"
    image: "/images/frontpage/robotcycle.jpg"
    content: "Field robotics is about going out into the world. MRG builds and deploys bespoke platforms — from cars to space robots to bicycles — equipped with cutting-edge sensors. These systems let us gather unique datasets in real environments, which we then make available to the wider community through careful curation and open science initiatives."
---
